# app.py
import streamlit as st
import pandas as pd
import numpy as np
import json, io, sys, subprocess, zipfile
from pathlib import Path

st.set_page_config(page_title="ì„œìš¸ë³´ì¦ SAAëª¨ë¸", layout="wide")
st.title("ğŸ“„ ì„œìš¸ë³´ì¦ SAAëª¨ë¸")

ASSETS = ["Fixed-Income","Global FI","Domestic Eq","Global Eq",
          "Private Credit","Private Eq","Real Estate","Infrastructure","Hedgefund"]
RISKY9 = ["Fixed-Income","Global FI","Domestic Eq","Global Eq",
          "Private Credit","Private Eq","Real Estate","Infrastructure","Hedgefund"]

# ---------------- í…œí”Œë¦¿ ì—‘ì…€ ìƒì„± ----------------
def make_template_bytes():
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as xw:
        # MU (ê¸°ì¤€ì—° ì˜ˆì‹œ 1Ã—10)
        mu_df = pd.DataFrame([ [0.025, 0.0251, 0.0323, 0.056, 0.064, 0.074, 0.0568, 0.046, 0.057, 0.052] ],
                             columns=ASSETS)
        mu_df.to_excel(xw, sheet_name="MU", index=False)

        # VOL (ê¸°ì¤€ì—° ì˜ˆì‹œ 1Ã—10)
        vol_df = pd.DataFrame([ [0.0, 0.028, 0.029, 0.146, 0.135, 0.163, 0.085, 0.015, 0.059, 0.053] ],
                              columns=ASSETS)
        vol_df.to_excel(xw, sheet_name="VOL", index=False)

        # CORR (9Ã—9, Risk-Free ì œì™¸) â€” ëŒ€ê°=1 ì˜ˆì‹œ
        corr_df = pd.DataFrame(np.eye(9), columns=RISKY9, index=RISKY9)
        corr_df.to_excel(xw, sheet_name="CORR")

        # BANDS (ìµœëŒ€ 3Ã—10) â€” 1í–‰ W_CURR, 2í–‰ MIN_BAND, 3í–‰ MAX_BAND
        bands = pd.DataFrame([
            [0.02, 0.7246, 0.1046, 0.0052, 0.0075, 0.0174, 0.0681, 0.0017, 0.0249, 0.0260],  # W_CURR
            [-10, -20, -10, 10, 10, -50, -10, -10, -10, -10],                               # MIN_BAND (%)
            [ 10,  10,  50,100, 50,  10, 400,3000, 400, 400],                                # MAX_BAND (%)
        ], columns=ASSETS)
        bands.to_excel(xw, sheet_name="BANDS", index=False)

        # PARAMS (Key, Value)
        params_kv = pd.DataFrame({
            "Key": ["TARGET_RETURN","PROB_LIMIT_VAR","PROB_LIMIT_SF","SF_YEARS","SF_N_MC","USE_ANTITHETIC",
                    "MC_TOPK","N_SCENARIOS","SEED_SCEN","AUM_KRW","LOSS_THRESHOLD_KRW","RF_ANN","SF_SEED"],
            "Value": [0.033, 0.01, 0.01, 5, 50000, True, 500, 10, 2029, 71693.1564, 300.0, 0.025, 1234]
        })
        params_kv.to_excel(xw, sheet_name="PARAMS", index=False)
    buf.seek(0)
    return buf

with st.sidebar:
    st.markdown("### 1) í…œí”Œë¦¿")
    st.download_button(
        "â¬‡ï¸ í…œí”Œë¦¿ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=make_template_bytes().read(),
        file_name="template.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

    # ---------------- ë‹¨ì¼ ì—‘ì…€ ì—…ë¡œë“œ ----------------
    st.markdown("### 2) íŒŒì¼ ì—…ë¡œë“œ")
    template_xlsx = st.file_uploader("template.xlsx ì—…ë¡œë“œ", type=["xlsx"])

    model_path = st.text_input("model.py ê²½ë¡œ", str(Path("model.py").resolve()))
    workdir = str(Path(model_path).parent.resolve())

def kv_to_dict(df):
    out = {}
    for _, row in df.iterrows():
        k = str(row[0]).strip()
        v = row[1]
        if isinstance(v, str):
            v_strip = v.strip()
            # True/False/None/ìˆ«ì íŒŒì‹± ì‹œë„
            if v_strip.lower() in ("true","false"):
                v = (v_strip.lower()=="true")
            else:
                try:
                    v = json.loads(v_strip)
                except Exception:
                    try:
                        v = float(v_strip)
                    except Exception:
                        pass
        out[k] = v
    return out

def build_overrides_from_excel(xls: pd.ExcelFile) -> str:
    lines = ["import numpy as np"]
    # MU
    if "MU" in xls.sheet_names:
        MU = pd.read_excel(xls, sheet_name="MU")
        if list(MU.columns) == ASSETS:
            arr = MU.to_numpy(dtype=float)
            if arr.shape == (1, 10):
                lines.append(f"MU_ANN = np.array({arr[0].tolist()}, float)")
                lines.append("MU_ANN_BY_YEAR = None")
            elif arr.shape == (5, 10):
                lines.append("MU_ANN_BY_YEAR = " + json.dumps(arr.tolist()))
            else:
                lines.append("# [warn] MUëŠ” (1Ã—10) ë˜ëŠ” (5Ã—10) ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            lines.append("# [warn] MU ì—´ ìˆœì„œê°€ ASSETSì™€ ë‹¤ë¦…ë‹ˆë‹¤.")
    # VOL
    if "VOL" in xls.sheet_names:
        VOL = pd.read_excel(xls, sheet_name="VOL")
        if list(VOL.columns) == ASSETS:
            arr = VOL.to_numpy(dtype=float)
            if arr.shape == (1, 10):
                lines.append(f"VOL_ANN = np.array({arr[0].tolist()}, float)")
                lines.append("VOL_ANN_BY_YEAR = None")
            elif arr.shape == (5, 10):
                lines.append("VOL_ANN_BY_YEAR = " + json.dumps(arr.tolist()))
            else:
                lines.append("# [warn] VOLì€ (1Ã—10) ë˜ëŠ” (5Ã—10) ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            lines.append("# [warn] VOL ì—´ ìˆœì„œê°€ ASSETSì™€ ë‹¤ë¦…ë‹ˆë‹¤.")
    # CORR (9Ã—9)
    if "CORR" in xls.sheet_names:
        CORR = pd.read_excel(xls, sheet_name="CORR", index_col=0)
        C = CORR.to_numpy(dtype=float)
        if C.shape == (9, 9) and list(CORR.columns)==RISKY9 and list(CORR.index)==RISKY9:
            lines.append("C_INPUT_RISKY = " + json.dumps(C.tolist()))
        else:
            lines.append("# [warn] CORRì€ (9Ã—9)ì´ê³  í–‰/ì—´ ë¼ë²¨ì´ RISKY9 ìˆœì„œì—¬ì•¼ í•©ë‹ˆë‹¤.")
    # BANDS (ìµœëŒ€ 3Ã—10)
    if "BANDS" in xls.sheet_names:
        B = pd.read_excel(xls, sheet_name="BANDS")
        if list(B.columns) == ASSETS and B.shape[1] == 10:
            arr = B.to_numpy(dtype=float)
            if arr.shape[0] >= 1:
                lines.append(f"W_CURR = np.array({arr[0].tolist()}, float)")
            if arr.shape[0] >= 2:
                lines.append(f"MIN_BAND = np.array({arr[1].tolist()}, float)")
            if arr.shape[0] >= 3:
                lines.append(f"MAX_BAND = np.array({arr[2].tolist()}, float)")
        else:
            lines.append("# [warn] BANDSëŠ” ì—´ 10ê°œê°€ í•„ìš”í•©ë‹ˆë‹¤ (ASSETS ìˆœì„œ).")
    # PARAMS (Key, Value)
    if "PARAMS" in xls.sheet_names:
        P = pd.read_excel(xls, sheet_name="PARAMS")
        if P.shape[1] >= 2:
            params = kv_to_dict(P.iloc[:, :2])
            for k, v in params.items():
                if isinstance(v, bool):
                    lines.append(f"{k} = {str(v)}")
                elif isinstance(v, (int, float)):
                    lines.append(f"{k} = {v}")
                else:
                    lines.append(f"{k} = {json.dumps(v)}")
    return "\n".join(lines) + "\n"

if st.button("â–¶ ëª¨ë¸ ì‹¤í–‰"):
    if not Path(model_path).exists():
        st.error(f"model.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    elif template_xlsx is None:
        st.error("í…œí”Œë¦¿ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    else:
        xls = pd.ExcelFile(template_xlsx, engine="openpyxl")
        ov_txt = build_overrides_from_excel(xls)
        overrides_path = Path(workdir) / "overrides.py"
        with open(overrides_path, "w", encoding="utf-8") as f:
            f.write(ov_txt)

        with st.expander("ğŸ“œ ì…ë ¥ ë°ì´í„°", expanded=False):
            st.code(ov_txt, language="python")


        # ê¸°ì¡´ ê²°ê³¼ ì œê±°
        expected = [
            "transition_5y_weights.csv",
            "transition_5y_metrics.csv",
            "transition_5y_equityVaR_prob.csv",
            "target_equityVaR_prob.csv",
            "shortfall_results.csv",
        ]
        for fn in expected:
            p = Path(workdir) / fn
            if p.exists():
                try: p.unlink()
                except: pass

        # model.py ì‹¤í–‰
        with st.spinner("model.py ì‹¤í–‰ ì¤‘..."):
            proc = subprocess.run(
                [sys.executable, Path(model_path).name],
                cwd=workdir,
                capture_output=True,
                text=True
            )

        with st.expander("ğŸ“œ ì‹¤í–‰ ë¡œê·¸ ë³´ê¸°", expanded=False):
            if proc.stdout:
                st.subheader("stdout")
                st.code(proc.stdout)
            if proc.stderr:
                st.subheader("stderr")
                st.code(proc.stderr)

        # ê²°ê³¼ í‘œì‹œ/ë‹¤ìš´ë¡œë“œ
        existing = []
        for fn in expected:
            p = Path(workdir) / fn
            if p.exists():
                existing.append(p)

        if not existing:
            st.warning("ê²°ê³¼ CSVê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŒŒë¼ë¯¸í„°/ë°´ë“œ/ëª©í‘œìˆ˜ìµë¥  ë“±ì„ ì ê²€í•´ ë³´ì„¸ìš”.")
        else:
            st.success(f"ìƒì„±ëœ ê²°ê³¼ íŒŒì¼ {len(existing)}ê°œ")
            for p in existing:
                st.markdown(f"**ğŸ“„ {p.name}**")
                try:
                    # 1) CSVë¥¼ ë¬¸ìì—´ë¡œ ì½ê³  â†’ ê³µë°±/ë¹ˆë¬¸ì â†’ NaN ì •ê·œí™”
                    df = pd.read_csv(p, dtype=str, keep_default_na=False, na_filter=False)
                    df = df.applymap(lambda x: np.nan if (x is None or (isinstance(x, str) and x.strip() == "")) else x)

                    # 2) ì™„ì „íˆ ë¹ˆ í–‰/ì—´ ì œê±°
                    df = df.dropna(axis=0, how="all").dropna(axis=1, how="all")

                    if df.empty:
                        st.info("ëª¨ë“  ì…€ì´ ë¹ˆ ê°’ì´ë¼ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
                    else:
                        # 3) ê°’ì´ ìˆëŠ” ìµœì†Œ ë°”ìš´ë”© ë°•ìŠ¤ë§Œ í‘œì‹œ
                        nonempty_rows = df.index[df.notna().any(axis=1)]
                        nonempty_cols = df.columns[df.notna().any(axis=0)]

                        r0, r1 = nonempty_rows.min(), nonempty_rows.max()
                        c0, c1 = nonempty_cols[0], nonempty_cols[-1]

                        df_trim = df.loc[r0:r1, c0:c1].fillna("").reset_index(drop=True)

                        # (ì„ íƒ) ì‹¤ì œë¡œ í•­ìƒ 5í–‰ê¹Œì§€ë§Œ ë³´ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ í•œ ì¤„ í™œì„±í™”
                        # df_trim = df_trim.head(5)

                        # 4) í–‰ ìˆ˜ì— ë§ì¶° ë†’ì´ ìë™ ì¡°ì •(ë¹ˆ ê³µê°„ ìµœì†Œí™”)
                        base, row_h, cap = 44, 28, 520   # í—¤ë”/í–‰ë†’ì´/ìµœëŒ€ë†’ì´
                        height = min(base + row_h * max(1, len(df_trim)), cap)

                        st.dataframe(df_trim, use_container_width=True, height=height)

                        # # í•„ìš” ì‹œ ì›ë³¸ ì „ì²´ëŠ” ì ‘ì–´ì„œ ì œê³µ
                        # with st.expander("ì›ë³¸ ì „ì²´ ë³´ê¸° (ì—¬ë°± í¬í•¨)", expanded=False):
                        #     st.dataframe(df.fillna(""), use_container_width=True, height=360)

                except Exception as e:
                    st.info(f"(ë¯¸ë¦¬ë³´ê¸° ë¶ˆê°€) {e}")

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                with open(p, "rb") as fh:
                    st.download_button(
                        f"â¬‡ï¸ ë‹¤ìš´ë¡œë“œ: {p.name}",
                        fh.read(),
                        file_name=p.name,
                        mime="text/csv"
                    )


            # ZIP ë¬¶ìŒ
            buf = io.BytesIO()
            with zipfile.ZipFile(buf, "w", zipfile.ZIP_DEFLATED) as zf:
                for p in existing:
                    zf.write(p, arcname=p.name)
            buf.seek(0)
            st.download_button("ğŸ“¦ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ", buf, file_name="model_outputs.zip", mime="application/zip")


